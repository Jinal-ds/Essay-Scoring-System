{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a606be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9783dcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f0a38b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17307, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "803191a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32062bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>Many people have car where they live. The thin...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>I am a scientist at NASA that is discussing th...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>People always wish they had the same technolog...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001bdc0</td>\n",
       "      <td>We all heard about Venus, the planet without a...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002ba53</td>\n",
       "      <td>Dear, State Senator\\n\\nThis is a letter to arg...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id                                          full_text  score\n",
       "0  000d118  Many people have car where they live. The thin...      3\n",
       "1  000fe60  I am a scientist at NASA that is discussing th...      3\n",
       "2  001ab80  People always wish they had the same technolog...      4\n",
       "3  001bdc0  We all heard about Venus, the planet without a...      4\n",
       "4  002ba53  Dear, State Senator\\n\\nThis is a letter to arg...      3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4efa472c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           full_text\n",
      "0  many people have car where they live. the thin...\n",
      "1  i am a scientist at nasa that is discussing th...\n",
      "2  people always wish they had the same technolog...\n",
      "3  we all heard about venus, the planet without a...\n",
      "4  dear, state senator this is a letter to argue ...\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def clean_essay(text: str) -> str:\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Replace inverted/fancy quotes with normal or remove\n",
    "    text = text.replace(\"“\", \"\").replace(\"”\", \"\")\n",
    "    text = text.replace('\"', \"\").replace(\"'\", \"\")\n",
    "    \n",
    "    # Remove multiple spaces, tabs, and newlines\n",
    "    text = re.sub(r\"\\s+\", \" \", text)  \n",
    "    \n",
    "    # Trim leading/trailing spaces\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply cleaning\n",
    "df[\"full_text\"] = df[\"full_text\"].astype(str).apply(clean_essay)\n",
    "\n",
    "print(df[[\"full_text\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21b5437f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['(bennging)luke was brave and went out to sea.he knew he might not come back but he still did it.he wanted to be a seagoing cowboy then he had to out into the sea. his friend helped him out alot so now he is a brave soilder like his friend. (middle)luke didnt want to go out at sea at first but now he does because he is not scared because he in brave and did his job.he got to where he was going the day after the world war ll.luke was lucky that he made it alive because the boomed cloesed to where he was going to. (middle) luke was also brave because he wanted to go out at sea even if his friends and family didnt like it.he was very brave and now he is in the army protecting the world from danger and harm. his friend made a good choice and i would the samething if i was lukes friend. (middle) my middle is that you can always have a friend but is that friend your true friend.if it is then you will know and they will be there to help you anything that you need help with.just like lukes friend helped him when he needed help the most.that is what friends are for to help out their friends who need their help. (end)that you cant do by yourself it takes two people to be friends and luke and his friend did what they had to and they did it bravely and as a team of friendship.',\n",
       "       '- car free cities- cities in europe and parts of the united states have taken a new trend, car free cities, this may be weird but the amount of good that comes from not having cars is increible. cars cause a greenhouse gases which are really bad for the environment. limiting car usage has many advantages and can help everyone. a place known as vauban, located in germany has over 5,500 residents and only 30 percent of them own cars and 57 percent sold a car to move there. people said that they lived much better lives without a car in (source 1), smog and toxic car feums dont clog the city air allowing it to be free for people to walk outside and smell the fresh air. some cities even enforce not to drive, such as paris if you drive through certre areas you will be fined 22-euros ($31). enough smog clear after people saw they were getting fined. there are some areas of the united states where greenhouse gas emissions are 50 percent, not only does this cause health related problems but also the it effects the environment, to help this the environmental protection agency is promotingcar reduced communities, and legislators are starting to act. this means that bills will be past to have certin areas have cars reduced. this increible idea really helps everyone and will help the future, some say its the end of the car culture. different bills are being passed to help communities reduce emission of the gases that come from cars that effect the environment and certin health problems. such as new york, they started a new bike-sharing program. some people within the ages of 16-21 have started new proritys and have organized themselfs to not need the use of a car. this is a prolong goal to help the environment and people, to create a better future. the excutive chairman of ford motor company. has laid out a business plan for a world in which vehicle ownership is impractical or undesirable.(source4) even car companys see the cars are bad and want change for a brighter future. limiting car usage or even no cars at all only have pros and is a very good idea for people who like to plan a good future and live in the suburbs. cars are bad for the environment and should be reduced to help out.',\n",
       "       '- change the electoral college,these citizens deserve to have their voices heard! many citizens are not aware of the main objective of the electoral college, and thus tend to debate in order to change how a president gets elected or leave it untouched with no mistakes fixed. for example, in the indefensible electoral college: why even the best-laid defenses of the system are wrong bradford plumer states that the electoral college is unfair to voters, because of the winner-take-all system in each state, candidates dont spend time in states they know they have no chance in winning. bladford plumer also stated that the electoral college is unfair, outdated, and irrational. in my firm belief, i am in favor of changing the electoral college, im sure of the consequences this will impact on society and history itself, but we need a system that grants equality with the citizens and the government. and the states that candidates are most likely willingly putting their vote on is on countries with significance. - however, not everyone has the same view. in in defense of the electoral college: five reasons to keep our despised method of choosing the president richard a. posner stated that the winner-take-all method of awarding the electoral votes induces the candidates- as we saw in 2012s election- to focus their campaign efforts on the toss-up states. posner also stated that the electoral college restores some of the weight in the political balance that states by population lose by virtue of the mal-apportionment of the senate decreed in the constitution. posner also said that the electoral college avoids the problem in which no candidate recieves a majority of the votes cast. to back his claim, he states that nixon in 1968 and clinton in 1992 both had only a 43 precent plurality of the popular votes while winning a majority in the electoral college (301 and 370 electoral votes, respectively). - continuing, it is clear that the electoral college does have its advantages but also contains disadvantages as well. im fully aware of the consequences this may have upon the constitution and the senate. now, i am not stating to get rid of the electoral college itself, but try to adjust and fix some tideous and unfair treatments to make it all equal. even though this could mean losing some interest from nominees, at least our system treats everyone with no difference. there are no superiors or inferiors in life. - in conclusion, i, not demand, but at least to try to have some concern for our population. bad reputation may mean a high loss of income from other states, knowing that this country has done some very sinister deeds that are simply despicable. listen to the complaints and hear their calling, after all, presidents always tend to drive their country to a better future, or am i wrong?',\n",
       "       ...,\n",
       "       '¨the face of mars¨ the ¨face¨ on mars is not an actually face at all. if there were life on mars, this life definitally wouldn´t be enormous as it say in the artical ¨unmasking the face on mars¨ in paragraph one. it states, ¨an enormous head nearly two miles from end to end seemed to be staring back at the cameras from a region of the red planet called cydonia.¨. another reason why the face isn´t life on mars it that in paragraph twelve gravin talks about how this face remind him of similar landforms back on earth. garvin also says how there are common landforms around the american west, so if there was life on mars why would there be simlar landmarks on earth? the staement garvin say is that ¨it reminds me of middle butte in the snake river plain of idaho,¨ garvin also mentions that the landform in idaho is the a lava dome that takes form of an isolated mesa about the same size as the face on mars. in conclusion, the face on mars isn´t any type of life or aliens because there are similar landforms in the american west of the u.s. like the lava dome in idaho that garvin says is similar in size and it looks the same. another quote in this article is ¨an enormous head nearly two miles from end to end seemed to be looking at back at the cameras.¨ now if there was to be life on mars, the life would not be enormous i can tell you that.',\n",
       "       '¨the face¨ people think that ¨the face¨ is created by aliens,but it is actually the face is a natural landform. so here is how i´m going to support my claim with evidence from the article. first of all,i claim that the ¨face¨ is just a natural landform. according to the article the scientists used the camera´s absolute maximum resolution so if there were objects in the picture they would see it. the rock formation resembles a human head,eyes,nose,and mouth, so we understand why people think it was a face created by aliens. second of all,according to paragraph 12 ¨what the picture actually shows is the martian equivalent of a butte or mesa-landforms common around the american west¨(12).if it was created by aliens it would not be hard to find because there would be more then just one.¨that´s a lava dome that takes form of an isolated mesa about the same height as the face on mars¨(12). in conclusion,i think that the face is a natural landform. there are evidence from the article to support my claims.¨malin´s team captured an extraordinary photo using the camera´s absolute maximum resolution¨(10).¨if there were objects in this picture like airplanes on the ground or egyptian-style pyramids or even small shacks,you could see what they were¨(11)!',\n",
       "       '¨wow look at that car it´s the kind of car that it can drive its self.¨ these are the words you may be hearing in the furture because people are starting to create cars that can drive themselfs. what do you think about this? do you think that its a good thing that people are making it or a bad thing? if i had to chose i believe driverless cars are bad because they might cause an accident, something could go wrong when you are using it, and maybe they could stop working out of nowhere. think about this if the car would cause an accident who will they blame it on the car or the person that was in it? some may never know but what if the driverless car cause an accident how would people react to it. it´s bad because then people would have to come up with a new law probably saying who would get the punishment if a accident would happen with the driverless car. in the text it says, ¨ new laws will be needed in order to cover liability in the case of an accident.¨ therefore i believe that the driverless car is bad and could prevent accidents while driving. if the driverless car would be made and people would get them something could go wrong at anytime without them noticing. driving the car would be putting the people at risk that are using it because something could go wrong with the car and could cause an accident that would put other people in danger. what if the technology in the car would fail at anytime it would put at risk for the person in the car and that won´t be good. therefore i believe that the driverless car could stop working while using it an it could put people in danger. in the text it says, ¨automakers are continuing their work on the assumption that the problems ahead will be solved.¨ even it says that in the text what if people would buy the driverless car and then it would stop working out of nowhere. if that would happen many people will see that it could stop working out of nowhere and it could put them in danger were their lives are at risk. if the driverless car would stop working out of nowhere would people get their money back, or would they get a new one, or would the company that sold them the car would just not give them nothing back? this is why i believe that the driverless car is not good because it could just stop working out of nowhere and then what would you do after that. in conclusion people should think about weither or not to get the driverless car because some stuff could happen to it. people should think about if getting the driverless car is really worth it getting because you never know it could just be a waste of money. i believe people should just drive themself to places so they could see the places around them and if possible go as fast as they want to go. therefore i believe that the driverless car could cause accidents, could fail of technology, and just stop working at anytime.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df['full_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce1e5df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6370476\n"
     ]
    }
   ],
   "source": [
    "df[\"word_count\"] = df['full_text'].astype(str).apply(lambda x: len(x.split()))\n",
    "total_words = df[\"word_count\"].sum()\n",
    "print(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b166f00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        word_count\n",
      "count  17307.00000\n",
      "mean     368.08667\n",
      "std      150.31376\n",
      "min      150.00000\n",
      "25%      253.00000\n",
      "50%      344.00000\n",
      "75%      452.00000\n",
      "max     1656.00000\n"
     ]
    }
   ],
   "source": [
    "print(df[[\"word_count\"]].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a4c606b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>many people have car where they live. the thin...</td>\n",
       "      <td>3</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>i am a scientist at nasa that is discussing th...</td>\n",
       "      <td>3</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>people always wish they had the same technolog...</td>\n",
       "      <td>4</td>\n",
       "      <td>550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001bdc0</td>\n",
       "      <td>we all heard about venus, the planet without a...</td>\n",
       "      <td>4</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002ba53</td>\n",
       "      <td>dear, state senator this is a letter to argue ...</td>\n",
       "      <td>3</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id                                          full_text  score  \\\n",
       "0  000d118  many people have car where they live. the thin...      3   \n",
       "1  000fe60  i am a scientist at nasa that is discussing th...      3   \n",
       "2  001ab80  people always wish they had the same technolog...      4   \n",
       "3  001bdc0  we all heard about venus, the planet without a...      4   \n",
       "4  002ba53  dear, state senator this is a letter to argue ...      3   \n",
       "\n",
       "   word_count  \n",
       "0         498  \n",
       "1         332  \n",
       "2         550  \n",
       "3         451  \n",
       "4         373  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d421b0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Jinal\n",
      "[nltk_data]     Vasita\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           full_text\n",
      "0  many people car live. thing dont know use car ...\n",
      "1  scientist nasa discussing face mars. explainin...\n",
      "2  people always wish technology seen movies, bes...\n",
      "3  heard venus, planet without almost oxygen eart...\n",
      "4  dear, state senator letter argue favor keeping...\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download stopwords (only once)\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Regex patterns\n",
    "URL_RE = re.compile(r\"(https?://\\S+|www\\.\\S+)\")\n",
    "HTML_RE = re.compile(r\"<.*?>\")  # keep only words and spaces\n",
    "\n",
    "def clean_essay(text: str) -> str:\n",
    "    text = text.lower()  # lowercase\n",
    "    \n",
    "    # Remove URLs and HTML\n",
    "    text = URL_RE.sub(\" \", text)\n",
    "    text = HTML_RE.sub(\" \", text)\n",
    "    \n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    \n",
    "    # Remove stopwords\n",
    "    words = [w for w in text.split() if w not in stop_words]\n",
    "    return \" \".join(words)\n",
    "\n",
    "# Apply cleaning\n",
    "df[\"full_text\"] = df[\"full_text\"].astype(str).apply(clean_essay)\n",
    "\n",
    "\n",
    "print(df[[\"full_text\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da83dc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3323346\n"
     ]
    }
   ],
   "source": [
    "df[\"word_count\"] = df['full_text'].astype(str).apply(lambda x: len(x.split()))\n",
    "total_words = df[\"word_count\"].sum()\n",
    "print(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b4a02e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>many people car live. thing dont know use car ...</td>\n",
       "      <td>3</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>scientist nasa discussing face mars. explainin...</td>\n",
       "      <td>3</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>people always wish technology seen movies, bes...</td>\n",
       "      <td>4</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001bdc0</td>\n",
       "      <td>heard venus, planet without almost oxygen eart...</td>\n",
       "      <td>4</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002ba53</td>\n",
       "      <td>dear, state senator letter argue favor keeping...</td>\n",
       "      <td>3</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id                                          full_text  score  \\\n",
       "0  000d118  many people car live. thing dont know use car ...      3   \n",
       "1  000fe60  scientist nasa discussing face mars. explainin...      3   \n",
       "2  001ab80  people always wish technology seen movies, bes...      4   \n",
       "3  001bdc0  heard venus, planet without almost oxygen eart...      4   \n",
       "4  002ba53  dear, state senator letter argue favor keeping...      3   \n",
       "\n",
       "   word_count  \n",
       "0         253  \n",
       "1         144  \n",
       "2         278  \n",
       "3         257  \n",
       "4         193  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "800ca30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\envs\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6baf4432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>many people car live. thing dont know use car ...</td>\n",
       "      <td>3</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scientist nasa discussing face mars. explainin...</td>\n",
       "      <td>3</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>people always wish technology seen movies, bes...</td>\n",
       "      <td>4</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>heard venus, planet without almost oxygen eart...</td>\n",
       "      <td>4</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dear, state senator letter argue favor keeping...</td>\n",
       "      <td>3</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17302</th>\n",
       "      <td>story challenge exploing venus informative pie...</td>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17303</th>\n",
       "      <td>technology changed lot ways live today. nowada...</td>\n",
       "      <td>4</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17304</th>\n",
       "      <td>dont like sitting around day great opportunity...</td>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17305</th>\n",
       "      <td>challenge exporing venus, author suggests stud...</td>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17306</th>\n",
       "      <td>venus worthy place study dangerous. reaosn the...</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17307 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               full_text  score  word_count\n",
       "0      many people car live. thing dont know use car ...      3         253\n",
       "1      scientist nasa discussing face mars. explainin...      3         144\n",
       "2      people always wish technology seen movies, bes...      4         278\n",
       "3      heard venus, planet without almost oxygen eart...      4         257\n",
       "4      dear, state senator letter argue favor keeping...      3         193\n",
       "...                                                  ...    ...         ...\n",
       "17302  story challenge exploing venus informative pie...      2          77\n",
       "17303  technology changed lot ways live today. nowada...      4         313\n",
       "17304  dont like sitting around day great opportunity...      2          96\n",
       "17305  challenge exporing venus, author suggests stud...      1         133\n",
       "17306  venus worthy place study dangerous. reaosn the...      2          68\n",
       "\n",
       "[17307 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('essay_id',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5a69490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>many people car live. thing dont know use car ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>scientist nasa discussing face mars. explainin...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>people always wish technology seen movies, bes...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001bdc0</td>\n",
       "      <td>heard venus, planet without almost oxygen eart...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002ba53</td>\n",
       "      <td>dear, state senator letter argue favor keeping...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17302</th>\n",
       "      <td>ffd378d</td>\n",
       "      <td>story challenge exploing venus informative pie...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17303</th>\n",
       "      <td>ffddf1f</td>\n",
       "      <td>technology changed lot ways live today. nowada...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17304</th>\n",
       "      <td>fff016d</td>\n",
       "      <td>dont like sitting around day great opportunity...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17305</th>\n",
       "      <td>fffb49b</td>\n",
       "      <td>challenge exporing venus, author suggests stud...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17306</th>\n",
       "      <td>fffed3e</td>\n",
       "      <td>venus worthy place study dangerous. reaosn the...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17307 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_id                                          full_text  score\n",
       "0      000d118  many people car live. thing dont know use car ...      3\n",
       "1      000fe60  scientist nasa discussing face mars. explainin...      3\n",
       "2      001ab80  people always wish technology seen movies, bes...      4\n",
       "3      001bdc0  heard venus, planet without almost oxygen eart...      4\n",
       "4      002ba53  dear, state senator letter argue favor keeping...      3\n",
       "...        ...                                                ...    ...\n",
       "17302  ffd378d  story challenge exploing venus informative pie...      2\n",
       "17303  ffddf1f  technology changed lot ways live today. nowada...      4\n",
       "17304  fff016d  dont like sitting around day great opportunity...      2\n",
       "17305  fffb49b  challenge exporing venus, author suggests stud...      1\n",
       "17306  fffed3e  venus worthy place study dangerous. reaosn the...      2\n",
       "\n",
       "[17307 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('word_count',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c01cd2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_col = 'full_text'\n",
    "score_col = 'score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bf115c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_score = df[score_col].min()\n",
    "max_score = df[score_col].max()\n",
    "df['normalized_score'] = (df[score_col] - min_score) / (max_score - min_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3a3389",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43af4676",
   "metadata": {},
   "outputs": [],
   "source": [
    "token=\"\"\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "413432d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(texts, max_len=256):\n",
    "    \"\"\"\n",
    "    Tokenizes a list of texts and returns tensors for the model.\n",
    "    \"\"\"\n",
    "    input_ids, attention_masks = [], []\n",
    "    for text in texts:\n",
    "        # Encode the text using the tokenizer\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,      # Add '[CLS]' and '[SEP]'\n",
    "            max_length=max_len,           # Pad/truncate to this length\n",
    "            padding='max_length',         # Pad to max_length\n",
    "            truncation=True,              # Truncate to max_length\n",
    "            return_attention_mask=True,   # Return attention mask\n",
    "            return_tensors='pt'           # Return PyTorch tensors\n",
    "        )\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    return torch.cat(input_ids, dim=0), torch.cat(attention_masks, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78a84080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the essays\n",
    "input_ids, attention_masks = tokenize_data(df[text_col].tolist())\n",
    "labels = torch.tensor(df['normalized_score'].values, dtype=torch.float32)\n",
    "\n",
    "# Create a TensorDataset from the tokenized data and labels\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f74ebc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 13845\n",
      "Validation set size: 3462\n"
     ]
    }
   ],
   "source": [
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print(f\"Training set size: {len(train_dataset)}\")\n",
    "print(f\"Validation set size: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "109883be",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4c73e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e85ccf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels=1,  # The number of output labels\n",
    "    token=token,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9d85091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5293b915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 5 ========\n",
      "  Average training loss: 0.0231\n",
      "\n",
      "======== Epoch 2 / 5 ========\n",
      "  Average training loss: 0.0169\n",
      "\n",
      "======== Epoch 3 / 5 ========\n",
      "  Average training loss: 0.0138\n",
      "\n",
      "======== Epoch 4 / 5 ========\n",
      "  Average training loss: 0.0105\n",
      "\n",
      "======== Epoch 5 / 5 ========\n",
      "  Average training loss: 0.0073\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n======== Epoch {epoch + 1} / {epochs} ========\")\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Clear gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(b_input_ids,\n",
    "                        token_type_ids=None,\n",
    "                        attention_mask=b_input_mask,\n",
    "                        labels=b_labels)\n",
    "\n",
    "        # Calculate loss and perform backpropagation\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model parameters\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"  Average training loss: {avg_train_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef9b036a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Validation...\n",
      "  Validation MAE: 0.50\n",
      "  Validation R-squared: 0.61\n"
     ]
    }
   ],
   "source": [
    "    print(\"\\nRunning Validation...\")\n",
    "    model.eval()\n",
    "    val_preds, val_labels = [], []\n",
    "\n",
    "    for batch in val_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(b_input_ids,\n",
    "                            token_type_ids=None,\n",
    "                            attention_mask=b_input_mask)\n",
    "\n",
    "        # Move predictions and labels to CPU to handle with NumPy\n",
    "        logits = outputs.logits.squeeze(1).cpu().numpy()\n",
    "        labels = b_labels.cpu().numpy()\n",
    "\n",
    "        val_preds.extend(logits)\n",
    "        val_labels.extend(labels)\n",
    "\n",
    "    # CONVERT LISTS TO NUMPY ARRAYS BEFORE CALCULATION\n",
    "    val_preds = np.array(val_preds)\n",
    "    val_labels = np.array(val_labels)\n",
    "\n",
    "    # Denormalize the scores for meaningful evaluation\n",
    "    denormalized_preds = val_preds * (max_score - min_score) + min_score\n",
    "    denormalized_labels = val_labels * (max_score - min_score) + min_score\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    mae = mean_absolute_error(denormalized_labels, denormalized_preds)\n",
    "    r2 = r2_score(denormalized_labels, denormalized_preds)\n",
    "\n",
    "    print(f\"  Validation MAE: {mae:.2f}\")\n",
    "    print(f\"  Validation R-squared: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0067ae2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"bert_essay_scoring_1.pt\")\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43a23928",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[32m     33\u001b[39m new_essay=\u001b[33m\"\u001b[39m\u001b[33mWhen cars where made by humans they put this device that is to have the car be more alarmed to the driver and everyone else that is in the car, but there are still some cars that are very old and don\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt have the same menufactors that are placed in the old cars that are like 1800s and 1900s. I think that the old cars should be put into some car meuseum or somthing to remind us how the very first engine car ever work without having a carage that has to have a horse to use as wheels even though that was a very very very very very very long time before even engine cars even excisted in time. i think that we\u001b[39m\u001b[33m'\u001b[39m\u001b[33mve impoved on the safety of everyone that is driving and that are still learning to drive and trying our hardest to keep people safe from harm but useally that doesn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt happen, we would have some difficulties with the cars that we are using today still needs some work to be done with them. I think it\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms a good idea to put more control on the car and less for the driver that has to drive the car. The only reason why we build cars and buses and trains and etc is to make us get to things like a if your running late for something and you need to get there really fast you could take your car and get there as fast as you can so your not offically late and not get fired and have to lose your job cause you were late for work. That\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms why we have cars to rely on and not our feet the whole time but most times if we dont want to use our car we can always walk there thats somewhere close and not far to walk like the gas station or the park or anything or if your just to dang LAZY to even walk that far then you would use a car or if you dont own a car you always use the bus to go where you want to go. It\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms not that hard to spend a little money on a bus toll to get to where you want to go and really it\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms not that hard at all but if it\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms for something really important then GO BUY A CAR i mean yeah cars are exspenive to even afford one but really if you save money then wouldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt have no problem at all on buying a car that has to fit your needs and get to places that you need to go.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m predicted_score = predict_score(new_essay, \u001b[43mmodel\u001b[49m, tokenizer, device, min_score, max_score)\n\u001b[32m     35\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mNew essay text:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnew_essay\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     36\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPredicted score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredicted_score\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "def predict_score(text, model, tokenizer, device, min_score, max_score, max_len=256):\n",
    "    \"\"\"\n",
    "    Predicts the score of a single essay.\n",
    "    \"\"\"\n",
    "    # Put the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Tokenize the input text\n",
    "    encoded_text = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_len,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    # Move tensors to the correct device\n",
    "    input_ids = encoded_text['input_ids'].to(device)\n",
    "    attention_mask = encoded_text['attention_mask'].to(device)\n",
    "\n",
    "    # Make the prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits.squeeze().cpu().numpy()\n",
    "\n",
    "    # Denormalize and round the score\n",
    "    predicted_score = round(logits * (max_score - min_score) + min_score)\n",
    "\n",
    "    return predicted_score\n",
    "\n",
    "# Example usage\n",
    "new_essay=\"When cars where made by humans they put this device that is to have the car be more alarmed to the driver and everyone else that is in the car, but there are still some cars that are very old and don't have the same menufactors that are placed in the old cars that are like 1800s and 1900s. I think that the old cars should be put into some car meuseum or somthing to remind us how the very first engine car ever work without having a carage that has to have a horse to use as wheels even though that was a very very very very very very long time before even engine cars even excisted in time. i think that we've impoved on the safety of everyone that is driving and that are still learning to drive and trying our hardest to keep people safe from harm but useally that doesn't happen, we would have some difficulties with the cars that we are using today still needs some work to be done with them. I think it's a good idea to put more control on the car and less for the driver that has to drive the car. The only reason why we build cars and buses and trains and etc is to make us get to things like a if your running late for something and you need to get there really fast you could take your car and get there as fast as you can so your not offically late and not get fired and have to lose your job cause you were late for work. That's why we have cars to rely on and not our feet the whole time but most times if we dont want to use our car we can always walk there thats somewhere close and not far to walk like the gas station or the park or anything or if your just to dang LAZY to even walk that far then you would use a car or if you dont own a car you always use the bus to go where you want to go. It's not that hard to spend a little money on a bus toll to get to where you want to go and really it's not that hard at all but if it's for something really important then GO BUY A CAR i mean yeah cars are exspenive to even afford one but really if you save money then wouldn't have no problem at all on buying a car that has to fit your needs and get to places that you need to go.\"\n",
    "predicted_score = predict_score(new_essay, model, tokenizer, device, min_score, max_score)\n",
    "print(f\"\\nNew essay text:\\n{new_essay}\")\n",
    "print(f\"Predicted score: {predicted_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fe3da5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m output_model_file = \u001b[33m\"\u001b[39m\u001b[33mbert_essay_scoring_1.pt\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Save the model (state dict is enough if you reload with the same class)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m torch.save(\u001b[43mmodel\u001b[49m.state_dict(), output_model_file)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_model_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# ------------------------\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# 2. Load model for inference\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# ------------------------\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Make sure you re-create the same model architecture before loading weights\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# ------------------------\n",
    "# 1. Save model after training\n",
    "# ------------------------\n",
    "output_model_file = \"bert_essay_scoring_1.pt\"\n",
    "\n",
    "# Save the model (state dict is enough if you reload with the same class)\n",
    "torch.save(model.state_dict(), output_model_file)\n",
    "print(f\"Model saved to {output_model_file}\")\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "# 2. Load model for inference\n",
    "# ------------------------\n",
    "# Make sure you re-create the same model architecture before loading weights\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "# Example: regression head (1 output neuron)\n",
    "loaded_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=1)\n",
    "loaded_model.load_state_dict(torch.load(output_model_file, map_location=device))\n",
    "loaded_model.to(device)\n",
    "loaded_model.eval()\n",
    "print(\"Model loaded successfully for inference!\")\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "# 3. Prediction function\n",
    "# ------------------------\n",
    "def predict_score(text, model, tokenizer, device, min_score, max_score, max_len=256):\n",
    "    \"\"\"\n",
    "    Predicts the score of a single essay.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    encoded_text = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_len,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    input_ids = encoded_text['input_ids'].to(device)\n",
    "    attention_mask = encoded_text['attention_mask'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits.squeeze().cpu().numpy()\n",
    "\n",
    "    # Denormalize (if you normalized labels during training)\n",
    "    predicted_score = round(logits * (max_score - min_score) + min_score)\n",
    "\n",
    "    return predicted_score\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "# 4. Example usage\n",
    "# ------------------------\n",
    "new_essay = \"When cars where made by humans they put this device...\"\n",
    "predicted_score = predict_score(new_essay, loaded_model, tokenizer, device, min_score, max_score)\n",
    "\n",
    "print(f\"\\nNew essay text:\\n{new_essay}\")\n",
    "print(f\"Predicted score: {predicted_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb7aff0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
